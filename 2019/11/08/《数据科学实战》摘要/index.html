<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>《数据科学实战》（Doing Data Science）笔记 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="马帅 2019年11月8日 书籍信息： 书名：《数据科学实战》（《Doing Data Science》）   作者：Rachel Schutt, Cathy O’Neil 译者：冯凌秉, 王群锋 出版社：中国工信出版集团 人民邮电出版社 介绍：本书来源于是哥伦比亚大学 数据科学导论课程内容">
<meta property="og:type" content="article">
<meta property="og:title" content="《数据科学实战》（Doing Data Science）笔记">
<meta property="og:url" content="http://yoursite.com/2019/11/08/《数据科学实战》摘要/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="马帅 2019年11月8日 书籍信息： 书名：《数据科学实战》（《Doing Data Science》）   作者：Rachel Schutt, Cathy O’Neil 译者：冯凌秉, 王群锋 出版社：中国工信出版集团 人民邮电出版社 介绍：本书来源于是哥伦比亚大学 数据科学导论课程内容">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/images/1572938490307.png">
<meta property="og:image" content="http://yoursite.com/images/1572941982173.png">
<meta property="og:image" content="http://yoursite.com/images/1572943691628.png">
<meta property="og:image" content="http://yoursite.com/images/1572946518148.png">
<meta property="og:image" content="http://yoursite.com/images/1572947116681.png">
<meta property="og:image" content="http://yoursite.com/images/1572947674785.png">
<meta property="og:image" content="http://yoursite.com/images/1572958133906.png">
<meta property="og:image" content="http://yoursite.com/images/1572958178205.png">
<meta property="og:image" content="http://yoursite.com/images/1572958548930.png">
<meta property="og:image" content="http://yoursite.com/images/1572958837700.png">
<meta property="og:image" content="http://yoursite.com/images/1572960989974.png">
<meta property="og:image" content="http://yoursite.com/images/1572962602910.png">
<meta property="og:image" content="http://yoursite.com/images/1573001343365.png">
<meta property="og:image" content="http://yoursite.com/images/1573001332966.png">
<meta property="og:image" content="http://yoursite.com/images/1573008634947.png">
<meta property="og:image" content="http://yoursite.com/images/1573009795212.png">
<meta property="og:image" content="http://yoursite.com/images/1573010971178.png">
<meta property="og:image" content="http://yoursite.com/images/1573016616343.png">
<meta property="og:image" content="http://yoursite.com/images/1573020394663.png">
<meta property="og:image" content="http://yoursite.com/images/1573021261301.png">
<meta property="og:image" content="http://yoursite.com/images/1573023644128-1573742490509.png">
<meta property="og:image" content="http://yoursite.com/images/1573025242595.png">
<meta property="og:image" content="http://yoursite.com/images/1573028322163-1573742600781.png">
<meta property="og:image" content="http://yoursite.com/images/1573028434702-1573742600782.png">
<meta property="og:image" content="http://yoursite.com/images/1573028818631-1573742600782.png">
<meta property="og:image" content="http://yoursite.com/images/1573032646760.png">
<meta property="og:image" content="http://yoursite.com/images/1573033006070.png">
<meta property="og:image" content="http://yoursite.com/images/1573047828215.png">
<meta property="og:image" content="http://yoursite.com/images/1573048157710.png">
<meta property="og:image" content="http://yoursite.com/images/1573049436053.png">
<meta property="og:image" content="http://yoursite.com/images/1573050190890.png">
<meta property="og:image" content="http://yoursite.com/images/1573051803657.png">
<meta property="og:image" content="http://yoursite.com/images/1573175183183-1573742712817.png">
<meta property="og:updated_time" content="2019-11-14T14:59:08.762Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="《数据科学实战》（Doing Data Science）笔记">
<meta name="twitter:description" content="马帅 2019年11月8日 书籍信息： 书名：《数据科学实战》（《Doing Data Science》）   作者：Rachel Schutt, Cathy O’Neil 译者：冯凌秉, 王群锋 出版社：中国工信出版集团 人民邮电出版社 介绍：本书来源于是哥伦比亚大学 数据科学导论课程内容">
<meta name="twitter:image" content="http://yoursite.com/images/1572938490307.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-《数据科学实战》摘要" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/08/《数据科学实战》摘要/" class="article-date">
  <time datetime="2019-11-08T15:11:48.047Z" itemprop="datePublished">2019-11-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      《数据科学实战》（Doing Data Science）笔记
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>马帅</p>
<p>2019年11月8日</p>
<p>书籍信息：</p>
<p>书名：《数据科学实战》（《Doing Data Science》）  </p>
<p>作者：Rachel Schutt, Cathy O’Neil</p>
<p>译者：冯凌秉, 王群锋</p>
<p>出版社：中国工信出版集团 人民邮电出版社</p>
<p>介绍：本书来源于是哥伦比亚大学 数据科学导论课程内容</p>
<a id="more"></a>



<p>[TOC]</p>
<h2 id="第一章-简介：什么是数据科学"><a href="#第一章-简介：什么是数据科学" class="headerlink" title="第一章 简介：什么是数据科学"></a>第一章 简介：什么是数据科学</h2><p>数据科学需要的技能：</p>
<p><img src="/images/1572938490307.png" alt="1572938490307"></p>
<p>学术界的数据科学家是：  一个学术界的数据科学家首先是个科学家，他接受了任何其他学科的训练（从社会学到生物学等各种学科），还要同大量的数据打交道，不管这些数据的结构、规模以及复杂程度如何，他都能挖掘出数据背后的意义，从而解决现实世界中的问题。  </p>
<p>工业界的数据科学家是：  他懂得如何从数据中抽取信息并且解释数据背后的意义，这需要掌握统计学和机器学习中的工具和方法，还要具备人文主义精神。  </p>
<h2 id="第二章-统计推断、探索性数据分析和数据科学工作流程"><a href="#第二章-统计推断、探索性数据分析和数据科学工作流程" class="headerlink" title="第二章 统计推断、探索性数据分析和数据科学工作流程"></a>第二章 统计推断、探索性数据分析和数据科学工作流程</h2><h3 id="2-1-大数据时代的统计学思考"><a href="#2-1-大数据时代的统计学思考" class="headerlink" title="2.1 大数据时代的统计学思考"></a>2.1 大数据时代的统计学思考</h3><p>我们所处的世界异常复杂，充满了随机性和不确定性，同时，这个世界又是一个巨大的数据生产机器。数据就是现实世界运转留下的痕迹。而这些痕迹会被如何展示出来，则取决于我们采用什么样的数据收集和样本采集方法。假如你是数据科学家，那么作为一个观察者，你要做的事是将具象的世界转化为抽象的数据，这个过程是绝对主观的，而非人们所想的那么中立客观。  将这一过程从数据收集中剥离出来，就能清晰地看到蕴藏其中的随机性和不确定性的两个源头：*<em>一是来自过程本身，二是来自数据采集方法。  *</em></p>
<p>你需要新的点子，将这些采集到的数据进行简化，使它们更易于理解，能够以一种更简明扼要的方式概述世界运行的规律，能够易于使用数学对其进行建模的数据，这称为<strong>统计估计量</strong>。  </p>
<p><strong>这一套从现实世界到数据，再由数据到现实世界的流程就是统计推断的领域。</strong>  </p>
<p>总体：指一组特定的对象或单位。</p>
<p>如果我们可以度量和提取这些对象的某些特征，就成为对总体的一组观察数据，习惯上用N表示对总体的观察次数。</p>
<p>样本：总体中选取的一个子集，用n表示。</p>
<p>研究者记录下样本的观察数据，根据样本特征推断总体的情况。采样的方法多种多样，<strong>有些采样方法会存在偏差，使得样本失真，而不能被视为一个缩小版的总体，去推断总体的特征。</strong>当这种情况发生时，基于样本分析所推断出来的结论常常是失真甚或完全错误的。  </p>
<p>由于采样过程不同所带来的不确定性有一个学名： 取样分布。  </p>
<p>总体和样本在大数据时代的意义：</p>
<ol>
<li>采样可以解决一些工程上对大数据处理的挑战；</li>
<li>采样偏差的存在；</li>
<li>采样的不确定性：由于采样过程不同而带来的不确定性称作取样分布；</li>
<li>大数据时代，新的数据类型要求我们在做采样时需更谨慎。</li>
</ol>
<p>大数据：大数据的大是相对的，只有当数据的规模对现有技术构成挑战时，才能称为“大”，  对于数据科学家来说，如果数据大到一台机器处理不了，就可以称其为“大数据”，因为她不得不学习使用一些全新的工具和方法去解决这一问题。  </p>
<p>大数据中的 4V 原则。这 4V 是指容量（Volume）、种类（Variety）、速度（Velocity）和价值（Value）。  </p>
<p>*<em>大数据时代只需要重视结论，放弃探究产生结果的原因吗？  *</em></p>
<p>答案是：错误。  </p>
<ol>
<li>N 永远不能代表全部。我们经常忽略我们最应该关心的事实</li>
<li>“让数据说话”这种观点是错误的。<strong>忽视因果关系是大数据法则的一种缺陷，而不是特征。忽视因果关系的模型无</strong><br><strong>助于解决现存问题，而只会增加更多问题。</strong></li>
</ol>
<p>按照惯例，数学公式里一般使用希腊字母表示参数，拉丁字母表示数据。  </p>
<p><strong>什么数据该用什么模型？这一半是艺术，一半是科学。</strong>  </p>
<p>概率分布是统计建模的基础，<strong>概率分布可以理解为对于可能结果的子集指定一个概率</strong>，概率分布用与其对应的函数来表<br>示。  </p>
<p>常用分布：</p>
<p><img src="/images/1572941982173.png" alt="1572941982173"></p>
<p><strong>拟合模型</strong>是指用观察数据估计模型参数的过程。  </p>
<p><strong>过拟合</strong>是指使用数据去估计模型的参数时，得到的模型并不能模拟现实情况，<strong>在样本以外的数据上效果不好</strong>。  </p>
<h3 id="2-2-探索性数据分析"><a href="#2-2-探索性数据分析" class="headerlink" title="2.2 探索性数据分析"></a>2.2 探索性数据分析</h3><p>探索性数据分析是建模的第一步。由贝尔实验室的数学家John Tukey开发，在探索性数据分析中，没有假设，也没<br>有模型，这里的“探索性”是指你对待解问题的理解会随着研究的深入不断变化的。</p>
<p>探索性数据分析的基本工具是图、表和汇总统计量。一般来说，探索性数据分析是一种系统性分析数据的方法，它展示了所有变量的分布情况（利用盒形图）、时间序列数据和变换变量，利用散点矩阵图展示了变量两两之间的关系，并且得到了所有的汇总统计量。换句话说，就是要计算均值、最小值、最大值、上下四分位数和确定异常值。  </p>
<p>在探索性数据分析中会引入许多图形，但是我们有必要在这里对探索性分析和数据可视化加以区分。探索性数据分析是数据分析的开端，而数据可视化（将会在第 9 章介绍）是在数据分析的最后一个环节，用于呈现数据分析的结论。在探索性数据分析中，图形只是帮助你理解数据。  </p>
<p><strong>观察你的数据，亲自去实践。</strong></p>
<h3 id="2-3-数据科学的工作流程"><a href="#2-3-数据科学的工作流程" class="headerlink" title="2.3 数据科学的工作流程"></a>2.3 数据科学的工作流程</h3><p><img src="/images/1572943691628.png" alt="1572943691628"></p>
<p>模型可能对结果没有影响（天气预报模型），也可能有影响（推荐网站推荐算法），在做任何分析时，都要将这种反馈考虑在内，以此对模型产生的偏差进行调整。模型不仅预测未来，它还在影响未来。  你都要将模型对你所观察和试图理解的现象的影响考虑在内。</p>
<h2 id="第三章-算法"><a href="#第三章-算法" class="headerlink" title="第三章 算法"></a>第三章 算法</h2><h3 id="3-1-机器学习算法"><a href="#3-1-机器学习算法" class="headerlink" title="3.1 机器学习算法"></a>3.1 机器学习算法</h3><p><strong>机器学习算法的应用主要有三个大舞台：预测、分类和聚类。</strong></p>
<ul>
<li><p>关于参数的解释</p>
<p>统计学家认为模型中的参数必须在现实世界中是有意义的。  而参数在软件工程师或计算机科学家的眼中  模型有些可以很复杂，甚至难以解释。有些模型甚至被叫作黑匣子，因为他们根本不知道模型内部到底是如何运作的。  </p>
</li>
<li><p>置信区间</p>
<p>在统计学中，置信区间和后验分布用来描述参数估计的不确定性。</p>
</li>
<li><p>显式假设的角色</p>
<p>统计模型会对数据的生成过程和数据的分布做出一些明确的假设（称作显式假设），统计推断的过程往往是建立在这些假设的基础之上。而本章稍后将要介绍的非参数检验方法，并不对概率分布做任何显式假设（可能是隐式的）。 </p>
</li>
</ul>
<h3 id="3-2-三大基本算法"><a href="#3-2-三大基本算法" class="headerlink" title="3.2 三大基本算法"></a>3.2 三大基本算法</h3><p>作为一个数据科学家，在熟练掌握各种算法之后，真正的挑战其实才刚刚开始。你需要根据特定问题和隐含的假设来敲板到底使用哪个算法或者模型。这种判断部分源自经验，这些都是建模的内功，是需要花时间和精力去领悟的。  </p>
<p><strong>问题之所以成为问题，就在于它的解决方案不是显而易见的。要时刻保持这样虚心的态度，这样当你去解决一个问题时，就会更加审慎。</strong>  </p>
<p>之所以说起这些，是因为我们总是笃信教科书教给我们的。教科书总是把问题和解决这些问题的方法都摆出来，然后告诉你哪类问题应该用哪种方法。（比如，用体重预测身高应该使用线性回归模型。）这样的教科书学习模式对于刚开始理解和学习线性回归模型是有一定好处的：因为新的知识被吸收是需要一定时间的，需要多加练习。但是，当你熟练掌握了这项技术后，真正的挑战在于你能否从一开始就要知道什么情况下应该使用线性回归模型。这里面存在的挑战往往是教科书不会告诉我们的。</p>
<p>学习这些算法的目的其实在于培养举一反三的能力：在遇到新的、非教科书式的问题时，我们要起码能看清解决问题的可能方向。  </p>
<p><img src="/images/1572946518148.png" alt="1572946518148"></p>
<h4 id="3-2-1-线性回归模型"><a href="#3-2-1-线性回归模型" class="headerlink" title="3.2.1 线性回归模型"></a>3.2.1 线性回归模型</h4><p>模型对于数据来说，主要是用来捕捉其中两个方面的信息：第一个是趋势（trend），第二个是变动幅度（variation）。</p>
<p>那么参数向量 b 到底如何估计呢？一个直观的想法是，如果存在一条最佳拟合的直线，那么所有样本数据点到这条的直线的距离应该是所有直线中最小的。</p>
<p><img src="/images/1572947116681.png" alt="1572947116681"></p>
<p>离差平方和表示为RSS（Residual Sum of Squares）：$RSS=\sum_i{(y_i - \beta x_i)^2}$</p>
<p><img src="/images/1572947674785.png" alt="1572947674785"></p>
<p><strong>一个自然的问题是，对于得到的预测值，我们有多大的自信认为它会十分接近真实值呢？</strong>这在统计学上叫作置信值的问题，解答它需要将模型的内涵稍作延伸。可以想象，如果用户的新好友数为 5，那么这些用户在网站上花费时间的预测值不可能只是一个定值 195.7秒，一个合理的情况是这些用户花费的时间都在 195.7 秒附近波动。因此，<strong>线性模型得到的预测值只是所有可能预测值的一个总体趋势，而围绕这个趋势的波动性还没有被模型考虑进来。</strong>  </p>
<p><strong>最小二乘模型的延伸：</strong></p>
<ul>
<li>增添一些关于模型误差项的假设<br>$$<br>y=\beta_0 + \beta_1 x + \epsilon<br>$$<br>其中的e是模型中的新加项，也称作“噪声”项，代表数据中不能被模型部分拟合的部分。它也称作误差项——$\epsilon$代表模型的实际误差，也就是实际观测值与真实回归直线上所得值的差距。真实的回归直线永远是未知的，而你只能通过$\hat{\beta}$估计。通常假设$\hat{\beta}$服从均值为0，方差未知的正态分布（不适用于金融数据），即$\epsilon = N(0,\sigma^2)$，那么我们可以从条件分布的角度解释线性回归对模型。也就是说，对于给定的 x， y 的条件分布是一个正态分布：$p(y|x) \sim N(\beta_0 + \beta_1 x , \sigma^2)$。回到刚才 x = 5 的情形，也就是说，对于所有新好友数为 5 的用户，他们在社交网站上花费的时间服从一个正 $\epsilon$ 态分布，该分布的均值为$\beta_0 + \beta_1 * 5$，方差为$\sigma^2$。$\beta_0$、 $\beta_1$ 以及$ \sigma^2 $ 的值需要从数据中估计。  </li>
</ul>
<p><img src="/images/1572958133906.png" alt="1572958133906"></p>
<p><img src="/images/1572958178205.png" alt="1572958178205"></p>
<p>  <strong>上面的方差估计量也叫作均方误差（mean squared error），它衡量的是预测值偏离实际观测值的程度。对于预测问题来说，均方误差是被广泛使用的一个误差估计量。</strong>  </p>
<p>  <strong>如何评估模型参数的估计值是否准确呢？，在R中，用$R^2$和p值这两个统计量，以及交叉验证。</strong></p>
<ul>
<li><p>得到多元回归模型。</p>
</li>
<li><p>变换</p>
<p>使用x的高阶项，得到多项式回归模型。我们知道，多项式回归模型不是线性回归模型。但是如果把 x 的高阶项看成新的变量，上式的表达形式仍然保持着“线性”的模样。</p>
</li>
</ul>
<p>你永远不能 100% 地肯定你的模型是正确的。数据量越多往往对于建模越有帮助，我们可以无限地接近真理，但永远无法到达那里。  </p>
<p><img src="/images/1572958548930.png" alt="1572958548930"></p>
<p><img src="/images/1572958837700.png" alt="1572958837700"></p>
<h4 id="3-2-2-K近邻模型（K-NN）"><a href="#3-2-2-K近邻模型（K-NN）" class="headerlink" title="3.2.2 K近邻模型（K-NN）"></a>3.2.2 K近邻模型（K-NN）</h4><p>k 近邻的主要想法是，根据属性值的相似度找到某个对象的相似对象们，并让其相似对象们一起“投票”决定该对象到底应该属于哪一类。如果有某两个或者更多个的类别投票数相同，那么就从这些类别中随机挑选一个作为该对象的类别值。</p>
<p> k 近邻方法需要解决两个核心问题：</p>
<ol>
<li>一是如何根据属性定义个体之间的相似性或者紧密程度。</li>
<li>到底如何才能确定一个最优的 k 值呢？  </li>
</ol>
<p><img src="/images/1572960989974.png" alt="1572960989974"></p>
<p>相似性/距离测度：</p>
<ul>
<li>欧几里得距离</li>
<li>余弦度：亮度两个实数向量 $\vec{x}$和 $\vec{y}$之间的相似程度，结果介于-1和1之间</li>
<li>Jaccard距离或相似度：  衡量两个集合之间的相似度  </li>
<li>Mahalanobis距离：也称作马氏距离，适用于两个实数向量。相比于欧氏距离，马氏距离考虑了两<br>个变量之间的相关关系，并且不用担心变量取值水平的问题。</li>
<li>Hamming距离：衡量两个字符串，字组或者具有相同长度的 DNA 序列之间的相似程度。Hamming 距离的计算方式其实十分简单，按照位置顺序的比对两个单词字母之间是否相同，每个位置上字母的不同，相应 Hamming 距离的值都增加 1。</li>
<li>Manhattan距离：测度两个 k 维实数向量之间的距离。  </li>
</ul>
<p>k的选择：</p>
<p>我们已经说过， k 对于 k 近邻模型来说是最为重要的参数，至于如何选择一个合适的（或者最优的）的 k 值，这要求你对数据本身的背景有深刻的理解，并且还需要通过不断地尝试（基于选定的模型评价标准）以确定一个合适的 k 值。对于二元分类问题，建议选择一个奇数k，“投票”方便，不会随机，当然偶数k也是可以的。</p>
<p><strong>k 近邻从模型形式上来看是一个非参数（nonparamatric）的方法</strong>，也就是说，对于数据的生成过程和数据的分布没有任何假设，也没有任何需要估计的参数。但即便作为一个非参数的方法，还是有一些隐含的假设：</p>
<p><img src="/images/1572962602910.png" alt="1572962602910"></p>
<p>在建模的过程中，基于模型评价的反馈，你可能会考虑添加某些特征变量，或者剔除某些特征变量。这些都叫作<strong>模型调优</strong>，好的模型应该经过仔细地调优。但在调整的过程中，也要注意避免过拟合的问题。  </p>
<h4 id="3-2-3-K均值算法"><a href="#3-2-3-K均值算法" class="headerlink" title="3.2.3 K均值算法"></a>3.2.3 K均值算法</h4><p>之前介绍的算法都属于监督性学习算法，它适用于 y 的观测值（对于分类问题来说就是待预测变量的标签值）已知的情况。在这个背景下，我们总是希望模型对 y 的预测越精确越好，这也是为什么在监督性学习中存在模型评价标准的原因。</p>
<p><strong>k均值算法是一种“非监督学习算法”</strong>，k均值聚类中，k就是这个聚类算法最后所得到的类别数。  </p>
<p><img src="/images/1573001343365.png" alt="1573001343365"></p>
<p><img src="/images/1573001332966.png" alt="1573001332966"></p>
<p>k均值算法有一些已知的缺点：</p>
<ul>
<li>k的选择是颇具艺术性的，当1&lt;=k&lt;=n，n是数据的样本量</li>
<li>收敛性问题：可能不存在唯一解，导致算法在两种可能解之间来回迭代而无法收敛</li>
<li>可解释性问题：也许最终的聚类结果很难给出合理的解释。<strong>这是k均值聚类最棘手的问题。</strong></li>
</ul>
<h2 id="第四章-垃圾邮件过滤器、朴素贝叶斯与数据清理"><a href="#第四章-垃圾邮件过滤器、朴素贝叶斯与数据清理" class="headerlink" title="第四章 垃圾邮件过滤器、朴素贝叶斯与数据清理"></a>第四章 垃圾邮件过滤器、朴素贝叶斯与数据清理</h2><h3 id="4-2-朴素贝叶斯模型"><a href="#4-2-朴素贝叶斯模型" class="headerlink" title="4.2 朴素贝叶斯模型"></a>4.2 朴素贝叶斯模型</h3><p>给定两个事件 x 和 y，其各自发生的概率分别为 p(x) 和 p(y)。它们联合发生的概率（表示为 p (x, y)） 以及它们相互发生的条件概率（比如说 p(y | x) 就表示给定事件 x 发生的情况下，事件 y 发生的概率）有如下关系：<br>$$<br>p(y|x)p(x)=p(x,y)=p(x|y)p(y)<br>$$<br>那么，  我们可以得到贝叶斯法则并进而得到关于 p ( y | x) 的概率表示（此处假设p(x) ≠ 0） :<br>$$<br>p(y|x)=\frac{p(x|y)p(y)}{p(x)}<br>$$<br>  其中的分母项 p(x) 可视作一个“正则常数”，并且通常来说得到它的值相对比较容易。  </p>
<h2 id="第五章-逻辑回归"><a href="#第五章-逻辑回归" class="headerlink" title="第五章 逻辑回归"></a>第五章 逻辑回归</h2><h3 id="5-2-分类器"><a href="#5-2-分类器" class="headerlink" title="5.2 分类器"></a>5.2 分类器</h3><p>分类模型：逻辑回归、决策树、随机森林、支持向量机、神经网络等等。</p>
<p>问题的背景是：给定一些数据和一个来自真实世界的分类问题，你需要决定：</p>
<ol>
<li><strong>使用哪一个分类器</strong></li>
<li><strong>应用何种优化方法训练分类器</strong></li>
<li><strong>选择什么样的损失函数</strong></li>
<li><strong>哪些特征变量对建模有用</strong></li>
<li><strong>如何评估模型的实际效果</strong></li>
</ol>
<p>某些模型需要大量的“运行时间”，比如说 k 近邻模型：当模型数据空间很大时，预测一个新数据的类别需要计算这个数据点的 k 个“邻居”，因此需要把所有的新旧数据点都存储在内存中，这通常会耗费大量的“运行时间”。而线性模型则不然，无论是模型更新还是用作实际预测，它的速度通常都令人满意。线性模型的更新过程只涉及新的数据，因此不需要把旧的数据也放在内存中，这极大地提高了模型的运行速度。一旦线性模型的参数估计完毕，只需要保存这些参数的估计值，预测新数据只涉及计算参数估计向量与新数据特征变量的点积的问题。</p>
<p><img src="/images/1573008634947.png" alt="1573008634947"></p>
<h3 id="5-3-逻辑回归"><a href="#5-3-逻辑回归" class="headerlink" title="5.3 逻辑回归"></a>5.3 逻辑回归</h3><p>传统的线性回归模型会输出任何一个介于负无穷和正无穷之间的实数值，而逻辑回归的输出值是实实在在的概率值，它位于 0 和 1 之间。因此可以说逻辑回归是为了分类模型而生的模型。</p>
<p><img src="/images/1573009795212.png" alt="1573009795212"></p>
<p><strong>模型评价标准总结：</strong></p>
<ul>
<li><p>提升度</p>
<p>提升度指的是分类模型的预测精度相比随机猜测模型的提升幅度。</p>
</li>
<li><p>准确度</p>
<p>模型的准备度指的是所有被正确预测的类别（包括阳性类和阴性类）</p>
</li>
<li><p>精确度</p>
<p>模型的精度指的是模型的真阳性值 / 所有的阳性值。也就是说，在所有被预测为阳性的<br>类中，其真实为阳性的比例。</p>
</li>
<li><p>召回率</p>
<p>召回率指的是模型的真阳性值 /（模型的真阳性值 + 模型的假阴性值）。也就是，在所<br>有应该被预测为阳性的类中，其真实被预测为阳性的比例。</p>
</li>
<li><p>F得分</p>
<p>之前我们没有提到任何关于 F 得分的内容，它是精度和召回度的调和平均值，其形式为： (2× 精确度 × 召回度 ) / ( 精确度 + 召回度 )。可以看出，它综合考虑到了精确度和召回度的不同特性。 F 得分还有很多变种，其区别主要在于精确度和召回度的权重不同。</p>
</li>
</ul>
<p><strong>如果我们想评价或比较模型输出的实际概率值的精确程度，可以用以下三种评价标准：</strong></p>
<ul>
<li><p>均方误差</p>
<p>指实际值与预测值之间的距离平方和</p>
</li>
<li><p>根均方误差</p>
<p>指均方误差的平方根</p>
</li>
<li><p>平均绝对离差</p>
<p>与均方误差不同的是，平均绝对离差计算的是预测值和实际值之间的绝对值距离，而不是平方距离。</p>
</li>
</ul>
<h2 id="第六章-时间戳数据与金融建模"><a href="#第六章-时间戳数据与金融建模" class="headerlink" title="第六章 时间戳数据与金融建模"></a>第六章 时间戳数据与金融建模</h2><p><img src="/images/1573010971178.png" alt="1573010971178"></p>
<h3 id="6-2-时间戳"><a href="#6-2-时间戳" class="headerlink" title="6.2 时间戳"></a>6.2 时间戳</h3><p>带有时间戳的数据是大数据时代的典型特征之一。</p>
<p>我们可以构建无数个指标或者新变量，上限就是你的想象力。但是，在构建新变量的时候，一个最基本的原则是：这些指标和变量的含义要清晰，要对理解数据有所帮助。</p>
<h3 id="6-5-金融数据处理"><a href="#6-5-金融数据处理" class="headerlink" title="6.5 金融数据处理"></a>6.5 金融数据处理</h3><p><img src="/images/1573016616343.png" alt="1573016616343"></p>
<p>标准化变换可以表示为：<br>$$<br>y_1 \mapsto \frac{y-\bar{y}}{\sigma_y}<br>$$<br>时间上的顺序代表着可能的因果关系，因此当你在训练模型以及引入新数据更新模型时一定要遵循数据的先后关系。永远不要在建模中作弊，不要使用还没有发生的样本外数据。</p>
<h2 id="第七章-从数据到结论"><a href="#第七章-从数据到结论" class="headerlink" title="第七章 从数据到结论"></a>第七章 从数据到结论</h2><h3 id="7-4-特征选择"><a href="#7-4-特征选择" class="headerlink" title="7.4 特征选择"></a>7.4 特征选择</h3><p>在数据建模中，数据科学家从数据中选取哪些特征变量，以怎样的形式加入模型，这个过程叫作特征选择。</p>
<p>原始数据中存在大量的冗余信息，比如很多相关性很大的变量。如果一股脑得全放进模型，必然不会有很好的效果。</p>
<p>Isabelle 在文中将主流的变量选择方法分为了三类，过滤型，打包型和内嵌型。</p>
<ul>
<li><p>过滤型</p>
<p><strong>过滤型是指根据特征变量与因变量之间的某个统计量的值将特征变量从大到小排列出来，再根据排序的顺序过滤掉一批变量。</strong>比如，可以用简单相关系数作为统计量。该方法的特点是<strong>每个变量都是独立过滤的，不考虑变量间的相互作用。</strong>因为其简单有效，通常会用在变量选择的第一步。</p>
<p>过滤型方法的好处是其容易计算，实施起来比较简单。但是<strong>，由于其并未考虑变量间的相关信息，可能会有一些副作用。</strong> Isabelle 在文中解释说，被过滤掉的两个“不重要”变量单独来看可能确实都不重要，但是放在一起可能会非常重要。变量之间的相互作用往往会将某些不重要的变量联系并组合成一个比较重要的特征。<br><strong>当然，统计量的类型并不限于简单相关系数。对于线性回归来说，一种较为常见的过滤器可以基于模型参数估计的 p 值或者模型拟合的 R 方。其操作方法是，用每一个特征变量单独建立回归模型并计算该变量参数估计的 p 值或者该模型的 R 方。最后，根据 p 值大小 7 或者 R 方的大小 8 对变量排序。</strong></p>
</li>
<li><p>包装型</p>
<p>在应用包装型的变量选择时，有两方面细节需要考虑：其一是选用什么样的算法选择最优子集，其二是选用什么样的“选择标准”衡量一个变量或者变量子集的优劣。</p>
<p>什么选法合适：</p>
<ul>
<li>逐步<img src="/images/1573020394663.png" alt="1573020394663">回归</li>
</ul>
</li>
</ul>
<p>  什么选择标准合适：</p>
<pre><code>一种可行的选择方法叫作“试错法”：尝试几个不同的选择标准，看模型在哪个标准下表现的更加稳健。  </code></pre><ul>
<li><p>R方</p>
</li>
<li><p>p值</p>
</li>
<li><p>AIC（赤池信息量准则）</p>
<p>$AIC=2k-2\ln(L)$</p>
<p>k为参数个数，$\ln(L)$是最大似然函数值。<strong>AIC越小模型效果越好。</strong></p>
</li>
<li><p>BIC（贝叶斯信息量准则）</p>
<p>$BIC=k \cdot \ln(n)-2\ln(L)$</p>
<p>k为参数个数，n为样本量，$\ln(L)$是最大似然函数值。<strong>AIC越小模型效果越好。</strong></p>
</li>
<li><p>熵</p>
</li>
</ul>
<ul>
<li>内嵌型</li>
</ul>
<p>因为分步回归本身的特点，选出的最佳变量子集很容易过拟合数据：模型的样本内拟合效果很好，但是样本外的预测效果却不然。</p>
<p><strong>决策树模型</strong></p>
<p>决策树方法的吸引力在于它非常直观。除数据科学领域以外，人们在日常生活中做决定时，也可以将大问题分解成一系列小问题，逐个解决。<strong>决策树的结构清晰、导向明确、非常容易理解，因此具有十分优良的可解释性。这也是决策树如此受欢迎的主要原因。</strong></p>
<p><img src="/images/1573021261301.png" alt="1573021261301"></p>
<p><strong>如何摆放决策树：总体原则是，在每一步，都先放上“信息量最大”的变量，从上往下地搭建决策树。</strong></p>
<p>熵代表一个变量所包含的信息量的大小，  信息量大小与变量的不确定性有着直接关系，一个变量的不确定性越高，其熵值越大。</p>
<p>用 X 表示用户是否续订我们的产品，那么我们必然想知道什么样的变量对 X的影响最大。这里我们需要定义信息增益（Information Gain, 用 IG（X, a）表示）的概念，对于变量 X，在给定一个变量值 a 的情况下， X 熵值的减少量：<br>$$<br>IG(X,a)=H(x)-H(X|a)<br>$$<br>用通俗的话讲， X 给定属性 a 的条件熵指的是在知道属性 a 的取值之后， X 熵值的减少量。因为熵代表了不确定性，也就是说，在知道 a 之后，我们对变量 X 有了新的认识，对它的不确定性减少了。从属性 a 的角度来说，就是它为我们更进一步了解 X 所带来的额外信息量。</p>
<p>决策树是一种迭代算法，先从第一个根节点开始选择变量进行拆分，直到所有的变量都已用尽，或者在某节点上只能对等拆分时，停止迭代。在每一个节点处，都选择可以最大化信息增益的变量用于拆分。</p>
<p><strong>随机森林模型</strong></p>
<p>随机森林是决策树模型的拓展，它基于 bagging（袋装）模型。 bagging 的全称是 bootstrap aggregating（解靴集成法）。该方法可以显著地提高模型的精度和稳健性，但会牺牲决策树模型本身的最大优点：可解释性。人们经常批评随机森林的黑匣子特征，认为从模型形式上来说，其基本不可以解释。然而，从模型设置来看，随机森林模型非常简单，它只有两个参数： N 代表森林中决策树的个数； F 代表每棵树上使用的（随机选取的）特征变量个数。</p>
<p><strong>bootstrapping（解靴法）。</strong>解靴是一种可放回的抽样方式，一个解靴样本（bootstrap sample）就是从原数据中有放回取出的 n个数据，因为抽样是可放回的，因此一个数据可能会被抽取多次，一些数据很可能一次也不会被抽到。至于 n 的大小，一般取所有数据量的 80%，当然这没有严格的规定。对于随机森林来说， n 可以理解为第三个参数。</p>
<p>建立随机森林模型，一般遵循以下两个步骤：</p>
<ol>
<li><p>从原始数据中抽取 N 个不同的解靴样本，每个样本都建立一个决策树。每个决策树只随机使用 F 个特征变量。</p>
</li>
<li><p>每个决策树的搭建都遵循之前讨论的原则，包括变量的选择，连续性变量的处理等。</p>
</li>
</ol>
<p><strong>每一个决策树都可以进行“事后剪枝”以避免过拟合，但对于随机森林模型来说，这完全没有必要。随机森林的一大特性就是对过拟合的免疫性：模型本身就吸收了数据中的特质方差，因此即使不做单个决策树的“事后剪枝”， 随机森林模型也不会过拟合</strong>。</p>
<p><img src="/images/1573023644128-1573742490509.png" alt="1573023644128"></p>
<h3 id="7-5-David-Huffaker：-谷歌社会学研究的新方法"><a href="#7-5-David-Huffaker：-谷歌社会学研究的新方法" class="headerlink" title="7.5 David Huffaker： 谷歌社会学研究的新方法"></a>7.5 David Huffaker： 谷歌社会学研究的新方法</h3><p>工程师们从产品立项的第一天起就尽量保证代码的质量，产品在小范围内实验后，会慢慢地开放给大众用户。因为谷歌的产品总是拥趸众多，因此他们不可能总是从头再来，产品开发的每一步都要脚踏实地。在小范围客户中验证产品可行性之后，再慢慢地扩大用户群，并在此过程中不断获取用户反馈并及时改善产品，这就是谷歌的产品开发哲学。</p>
<p><strong>当你向大数据迈进的路上，不要被定量分析蒙蔽了双眼。简单的、基于逻辑的定性分析对于更加深刻地理解数据同样重要。像定性调查分析这样的传统工具，有时候反而能取得奇效。</strong></p>
<h2 id="第八章-构建面向大量用户的推荐引擎"><a href="#第八章-构建面向大量用户的推荐引擎" class="headerlink" title="第八章 构建面向大量用户的推荐引擎"></a>第八章 构建面向大量用户的推荐引擎</h2><p><strong>高纬度问题</strong></p>
<p>解决高维度问题的两大杀手锏是奇异值分解（Singular Value Decomposition）和主成分分析（Principal Component Analysis）。</p>
<p>在这个降维过程中发生了两件值得注意的事情：其一是很多变量的被一个隐含变量所涵盖，其二是这个隐含变量不可观测。</p>
<p>“重要”在这里指的是该隐含变量可以解释数据中绝大部分的方差。如果可以用很少的“隐含变量”就能解释数据中绝大部分的方差，那么这些隐含变量就是“重要”的。</p>
<p>而二元变量所包含的信息往往少于连续性变量和多类别变量。Hunch 的研究人员就发现，问卷中多设计一些比对问题（comparison question）能够带来更好的推荐效果。</p>
<p><img src="/images/1573025242595.png" alt="1573025242595"></p>
<h2 id="第九章-数据可视化与欺诈侦测"><a href="#第九章-数据可视化与欺诈侦测" class="headerlink" title="第九章 数据可视化与欺诈侦测"></a>第九章 数据可视化与欺诈侦测</h2><ul>
<li><p>机器学习不等于写R程序</p>
<p>机器学习根植于数学，它的最终成果是通过编程实现的软件产品的有机组合。要做好机器学习，你必须具备相当的程序开发技能，能写一手漂亮的程序，且这些程序要具备良好的可读性和可实现性。程序的最终受众是广大用户而不是你自己，因此你应该确保程序经得起反复推敲，并能够实现产品化。</p>
</li>
<li><p>数据可视化不仅仅是一张好图<br>对于一家优秀的数据产品公司来说，可视化应该成为产品开发文化的一个重要组成部分。好的数据产品应该有经过仔细构思的可视化模块，同时，好的可视化模块能够带给用户更好的产品体验。</p>
</li>
<li><p>机器学习与可视化推动着人工智能的发展<br>人类本身的认知能力是十分有限的。然而，借助于数据和数据科学，我们有如披上了超人的外衣，得以在原本一片混沌的信息世界中自<img src="/images/1573028322163-1573742600781.png" alt="1573028322163">由翱翔。</p>
<p><img src="/images/1573028434702-1573742600782.png" alt="1573028434702"></p>
<p><img src="/images/1573028818631-1573742600782.png" alt="1573028818631"></p>
</li>
</ul>
<h2 id="第十章-社交网络与数据新闻学"><a href="#第十章-社交网络与数据新闻学" class="headerlink" title="第十章 社交网络与数据新闻学"></a>第十章 社交网络与数据新闻学</h2><p>为社交网络分析不仅要考虑到个人，更要注重人与人之间关系的研究，这是社交网络的本质特征。</p>
<p>如果两个节点之间有关系，则从表现形式上来看，它们之间必有线相连。从网络连接的角度来说，对某人点赞与实际生活中与某人住在一起没有形式上的差别，都可以用一条边连接起来。一个社交网络就是所有节点与边的集合。</p>
<p><strong>谁在这个网络中的重要性最大？</strong></p>
<ul>
<li>自由度，这通常指的是在网络中有多少人与你有边相连。</li>
<li>“紧密度”。 如果你的好友与你的连接越紧密，你们的“紧密度”就越高。</li>
</ul>
<p><img src="/images/1573032646760.png" alt="1573032646760"></p>
<p>即便个体的改变是巨大的，但却对整体没有显著影响。也就是说，像社交网络分析这样注重群体网络研究的方式，会比案例 - 属性数据那样注重个体研究的方式带给研究人员更深层次的洞察力。</p>
<p>网络节点间的连接方式有两种：有向连接和无向连接。</p>
<p>可视化是直观地报道和解释数据的最有效的工具。</p>
<p>统计学对数据新闻学的重要性同样不言而喻。统计学是数据分析的基石，是我们思考的方式。</p>
<p>另外两项对于数据新闻工作者来说至关重要的技能是：交流与展示。如何把一个个复杂的故事以通俗、容易理解的方式展示给读者，是数据新闻工作的基本要求。同样，数据新闻工作者要时刻准备着回答读者提出的各种问题，把问题转化成数据分析任务，再将分析的结果以同样通俗和容易理解的方式反馈给读者。</p>
<h2 id="第十一章-因果关系研究"><a href="#第十一章-因果关系研究" class="headerlink" title="第十一章 因果关系研究"></a>第十一章 因果关系研究</h2><p>到底什么是因果关系？说白了，如果你想要做出某种行为导致了某个结果的论断，这便是因果关系推断。因果关系模型并不是一套完全不同于预测模型的统计方法。恰好相反，它其实是根植于传统预测模型（如逻辑回归、线性回归）的框架内的。但是，你的思路和目标就不再是优化模型以提高预测的准确性了，而是尽力分离出变量之间的因果关系。</p>
<h3 id="11-1-相关性并不代表因果关系"><a href="#11-1-相关性并不代表因果关系" class="headerlink" title="11.1 相关性并不代表因果关系"></a>11.1 相关性并不代表因果关系</h3><p>确定两个变量间的因果关系是统计学的一大难题。</p>
<p><img src="/images/1573033006070.png" alt="1573033006070"></p>
<p>人们通常花大力气研究那些简单易测的变量，但这些变量却并未能测出他们想要的东西，而大家不管三七二十一，都根据这些变量的研究结果做出决策，这样的研究是非常不负责任的。</p>
<h3 id="11-2-OK-Cupid的发现"><a href="#11-2-OK-Cupid的发现" class="headerlink" title="11.2 OK Cupid的发现"></a>11.2 OK Cupid的发现</h3><p>观察性研究指的是数据的生成过程没有受人为干扰，是自然生成的。这与人工设计的实验正好相反——在实验中各种因素都被人为控制，以研究某一个特定因素对实验结果的影响。</p>
<p><strong>控制实验</strong></p>
<p>当一个变量同时影响到“实验”本身，以及“实验”的结果时，它就是一个干扰因子。</p>
<h3 id="11-3-黄金准则：随机化临床实验"><a href="#11-3-黄金准则：随机化临床实验" class="headerlink" title="11.3 黄金准则：随机化临床实验"></a>11.3 黄金准则：随机化临床实验</h3><p><strong>我们到底应该怎么做才能确定变量之间的因果关系呢？</strong></p>
<p><strong>确立因果关系的黄金准则是使用随机化实验。顾名思义，随机化实验的关键在于随机化：样本被随机化为两个子样本，一个作为实验组（接受处理），另一个作为控制组。随机化之后，两组样本的表现差异就可以视作是“处理”因素引起的。从统计学角度来看，随机化保证了两个子样本都是来自同一个总体的同质样本，因此对于两个子样本来说，潜在干扰因子的可能影响是同等的。这从理论上排除了所有潜在干扰因子的影响。</strong></p>
<p>随机实验的效果很好，因为在随机化的过程中，所有可能成为干扰因子的因素都被排除了（比如是否有吸烟史）。随机化保证了有抽烟史的人将会以同样的概率被分到两个子样本中，于是“吸烟史”这样一个干扰因子就被随机化排除了。</p>
<p><strong>随机实验的绝妙之处在于，不单是我们所能想到的，就连那些我们很难考虑到的无数其他干扰因子的影响，也被排除了。</strong></p>
<p>因此，虽然我们可以通过算法针对某些变量找到一些不错的划分，但是这些划分不可能对所有变量都有同样好的效果。这也正是我们需要随机化的原因，因为随机化无论对于我们能考虑到的变量还是没有考虑的变量都有同等的效果。</p>
<p>当随机实验的条件满足时，它是解决因果推断问题的黄金法则。然而，随机实验也常常由于道德和现实条件的限制而变得不可行</p>
<h3 id="11-5-退一步求其次：关于观察性研究"><a href="#11-5-退一步求其次：关于观察性研究" class="headerlink" title="11.5 退一步求其次：关于观察性研究"></a>11.5 退一步求其次：关于观察性研究</h3><p>观察性研究是当控制实验（随机实验）不可行时而采用的一项分析因果关系的实证性研究方法。</p>
<p>我们可以利用因果关系图来呈现因果关系建模的概念。因果关系图中的干扰因子，实验的“处理”和实验的“结果”都用节点表示；用箭头表示<br>因果关系的方向。换句话说，箭头的出发节点是因果关系的“因”， 而所指向的是“果”。</p>
<p><img src="/images/1573047828215.png" alt="1573047828215"></p>
<p>对于观察性数据来说，最重要的莫过于确定如何把样本分成实验组和控制组。倾向性得分匹配法就是最为著名的方法。从本质上来讲，倾向性得分法是一种伪随机分组法（pseudo-random experiment），人为控制组的分类原则是尽量选择与实验组总体特征特别相像的个体（这些个体以同样的概率出现在实验组和控制组中）。</p>
<p>这也是倾向性得分匹配的先天性缺陷：我们永远无法确信已经考虑到了所有该考虑的因素。然而，它的优越性在于，如果可能的干扰因子都能被考虑到，那么在倾向性评分匹配模型背景下的因果关系推断是合理和有效的。</p>
<h3 id="11-6-三个小建议"><a href="#11-6-三个小建议" class="headerlink" title="11.6 三个小建议"></a>11.6 三个小建议</h3><p><img src="/images/1573048157710.png" alt="1573048157710"></p>
<h2 id="第十二章-流行病学"><a href="#第十二章-流行病学" class="headerlink" title="第十二章 流行病学"></a>第十二章 流行病学</h2><p><img src="/images/1573049436053.png" alt="1573049436053"></p>
<p>Madigan 觉得，简洁明了的可视化对解释分析结果确实有很大帮助。</p>
<p>分层（分类）的想法有时候不仅没有解决问题，反而带来了很多新的问题：因果关系的估计结果往往变得扑朔迷离。因此，当你在解决干扰因子问题时，至于到底该不该用分层法，需三思而后行。</p>
<p>一团队的论文（<a href="http://1.usa.gov/16UfNjZ）宣称口服磷酸双酯会增加患癌的风险，而另外一篇发表于" target="_blank" rel="noopener">http://1.usa.gov/16UfNjZ）宣称口服磷酸双酯会增加患癌的风险，而另外一篇发表于</a> JAMA 的论文（<a href="http://1.usa.gov/1hi2kbj）则表示口服磷酸双酯不会增加患食管癌的风险。他们分析的数据甚至来自于同一个数据库，却得到了截然相反的结论。其实这样的研究成果具有对立性的现象在医学界还有很多。" target="_blank" rel="noopener">http://1.usa.gov/1hi2kbj）则表示口服磷酸双酯不会增加患食管癌的风险。他们分析的数据甚至来自于同一个数据库，却得到了截然相反的结论。其实这样的研究成果具有对立性的现象在医学界还有很多。</a></p>
<p>0.5 的 AUC代表该模型与瞎猜没有任何区别。</p>
<h2 id="第十五章-从竞赛中学到的：数据泄露和模型评价"><a href="#第十五章-从竞赛中学到的：数据泄露和模型评价" class="headerlink" title="第十五章 从竞赛中学到的：数据泄露和模型评价"></a>第十五章 从竞赛中学到的：数据泄露和模型评价</h2><p><img src="/images/1573050190890.png" alt="1573050190890"></p>
<p>这看起来是一个愚蠢并且显而易见的错误，谁也不会犯这种错误。也许如此，但是这种事时有发生，而且在深入理解数据、弄明白特征和预测变量的含义前，你无法预料到这种事情会发生。想一下，如果这种“显而易见”的错误都会犯，那么对于那些不那么明显的情况更应该加倍小心。同时，这也是在本书中没有给予充分强调的一个例子，与网络爬虫和洋气的机器学习算法相比，通过一些基本的检查，确保一切如你所料，往往会让你走得更远。这可能看起来不够酷，不够吸引人，但它管用，是一个很好的经验。</p>
<p><img src="/images/1573051803657.png" alt="1573051803657"></p>
<p>在本书的讨论中，评价模型好坏的标准之一是准确度，尤其是对于那些二元分类问题。Claudia 认为准确度不是衡量模型的一个好的指标，使用准确度有什么问题？首先，它显然不适合用来评价回归模型；其次，对于那些大部分输出为 1 的二元分类模型也不适合，一个很傻的模型可能拥有很高的预测准确度，却不是一个好的模型（它预测所有的输出都是 1），一个好的模型却可能拥有较低的准确度。</p>
<h2 id="第十四章-数据工程：MapReduce、Pregel、Hadoop"><a href="#第十四章-数据工程：MapReduce、Pregel、Hadoop" class="headerlink" title="第十四章 数据工程：MapReduce、Pregel、Hadoop"></a>第十四章 数据工程：MapReduce、Pregel、Hadoop</h2><p>当你处理数据时，如果一个计算单元容纳不下这些数据，则这就是大数据。现在，大数据指不能使用一台计算机处理的数据。</p>
<h2 id="第十五章-听听学生们怎么说"><a href="#第十五章-听听学生们怎么说" class="headerlink" title="第十五章 听听学生们怎么说"></a>第十五章 听听学生们怎么说</h2><p><strong>非常值得一读</strong></p>
<h2 id="第十六章-下一代数据科学家、自大狂和职业道德"><a href="#第十六章-下一代数据科学家、自大狂和职业道德" class="headerlink" title="第十六章 下一代数据科学家、自大狂和职业道德"></a>第十六章 下一代数据科学家、自大狂和职业道德</h2><p>本书有两个主要目标，一是告诉读者数据科学家是干什么的，二是教会读者一些数据科学家的技能。</p>
<p>我们鼓励下一代数据科学家成为提出问题并解决问题的人，深入思考合适的设计和流程，负责任地使用数据，让这个世界变得更好，而不是更坏。</p>
<p>我们认为下述一些思想品质有助于解决问题 1：持之以恒，思考你的大脑是如何思考的，不钻牛角尖，能灵活地思考，永远追求准确度，带有同理心地去思考问题。</p>
<p>说到这里，你是否想过，为什么人们不知道某件事时，不直接说“不知道”？这种现象，可以被部分解释为“达克效应”， <strong>无知比知识更容易招致自信。</strong><br><strong>基本上，在某件事上不擅长的人，不知道他们在这件事上有多无知，因此容易高估自己，而那些擅长某事的人，却因为了解，反而低估了他们的能力。知识削弱了人们的自信。将这些谨记在心，不要高估，也不要低估自己，确保说到的东西可以做到，和其他数据科学家交谈时不要忘记随时检查自己。</strong></p>
<p><img src="/images/1573175183183-1573742712817.png" alt="1573175183183"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/11/08/《数据科学实战》摘要/" data-id="ck2yrzwxy0001e8qq6u9rujvt" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2019/08/05/My First Blog/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">My First Blog</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/11/08/《数据科学实战》摘要/">《数据科学实战》（Doing Data Science）笔记</a>
          </li>
        
          <li>
            <a href="/2019/08/05/My First Blog/">My First Blog</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>